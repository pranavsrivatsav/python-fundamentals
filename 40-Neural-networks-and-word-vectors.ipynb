{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network in simple words\n",
    "- Each neuron is assinged a subtask, and the results of these subtasks are passsed to other neurons which repeats this process until an overall result is obtained.\n",
    "- This network of neurons is called neural network.\n",
    "\n",
    "#### Training of a neural network\n",
    "- A neural network is trained over large amounts of data.\n",
    "- Let's say for example, we are training a neural network to identify a koala bear.And we feed it a lot of images with some of them Koalas and others not.\n",
    "- In the training stage, as the neural network parses through one data after another, it comes with a final result. This result is passed over to a supervisor.\n",
    "- supervisor: The supervisor is someone who holds the correct result. So everytime supervisor spots an error, it communicates the error back to the neurons.\n",
    "- This is called backward error propogation. And the neurons with the help of fancy mathematics are reinforced by the errors and successes, and proceed to improve their skill of learning to identify a Koala.\n",
    "\n",
    "\n",
    "#### How does a neural network come up with a result\n",
    "- Ok, so let's once again look at the challenge of identifying of a Koala bear.\n",
    "- And we have a set of neurons trying to match the eyes, another the ears, another the nose\n",
    "- The results from these set of neurons is passed into a neuron whose subtask is just to match the face to that of a koala using the said results.\n",
    "- Similarly there will be sub networks for the body and the legs as well.\n",
    "- So, when it comes to something like identifying or recognizing a live subject like a human or animal, more weightage is naturally provided to the face.\n",
    "- So here as the results come in from the face, body and the ears sub network, we can imagine the final layer of neurons to come up with a result by weighing these results appropriately and adding them together for the final result.\n",
    "    - (w<sub>face</sub> \\* result<sub>face</sub>) + (w<sub>body</sub> \\* result<sub>body</sub>) + (w<sub>legs</sub> \\*result<sub>legs</sub>) = result<sub>koala</sub>\n",
    "    - so in this case, the weights can be   \n",
    "        - w<sub>face</sub> = 0.65\n",
    "        - w<sub>body</sub> = 0.20\n",
    "        - w<sub>legs</sub> = 0.15\n",
    "- Similarly each level below will have a weightage based on relevant parameters. These weights are our switches, neural learning is done by tweaking these switches to slowly learn a skill, in this case how to recognize a koala.\n",
    "- Now, once we have the result, the supervisor will communicate the correct result, if the result is wrong, the networks tweak some weights around for the next attempt by comparing it's result with the correct result. \n",
    "    - NOTE: all these results will be in computer understandable numerics like vectors, so the network can actually do a proper comparison and learn.\n",
    "- If during the next attempt, the result is correct, this is a reinforcement that the tweaked weights post the previous attempt is in the right direction, and the tweaks again take place in that direction. This is a form of reinforcement learning, where our network makes a change and learns based on the reinforcement gained by the success or failure of the attempt.\n",
    "- The quality of results depend upon the no of weights aka switches, which is dependent on the number of neurons and the layers in the neural network.\n",
    "- So, an important part of creating a neural network to learn a skill, is to get the correct balance between performance and precision which are both dependent on the size of the neural network.\n",
    "- As this training is done millions of times on millions of sets of data, the neural network becomes adept at the skill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do training neural networks create Word Vector Models?\n",
    "\n",
    "- 3 components in place:\n",
    "    - A data\n",
    "    - A problem based on the data to solve\n",
    "    - The side effect of solving the problem\n",
    "\n",
    "- The side effect of solving a problem on a set of data using a neural network is what yields us the vector associated with the word.\n",
    "\n",
    "- So now we are clueless, so what problem are we trying to solve on what data for us to yield a word vector.\n",
    "- Let's say we have a passage.\n",
    "    - Once upon a time, in the heart of an ancient kingdom, there reigned a wise and noble king named Arjun. Under his rule, the kingdom flourished with prosperity and peace, guided by his council of learned ministers. Among them, the chief minister, Rajan, was revered for his strategic brilliance and unwavering loyalty.\n",
    "    - Now let us introduct a problem to find the missing word for every set of 5 words:\n",
    "    - Like \"once ____ a time ,\" | \"a ____ and noble king\"\n",
    "    - So, first we will load the data into neural network, and each word in the data will be assigned an initial vector.\n",
    "    - And now the neural network will start to solve all the problems in the provided data.\n",
    "    - Let's now focus on the problem to find the missing word in \"a __ and noble king\".\n",
    "        -  so as the neural network tries to match each word in the blank, with every result, it updates the vector of the word based on the context of the problem, here the context is nothing but the surrounding word vectors and their placement.\n",
    "        - and as it learns that \"wise\" is the correct answer, it updates the vector of the word \"wise\" based on this reinforcement.\n",
    "    - So, we can imagine that if we train a neural network to solve this problem on a large set of data, the neural network will atleast get to a point, where atleast with respect to the data it can solve the problem more often than not, hence the quality of data is important.\n",
    "\n",
    "-  There are 2 types of commom problems that are solved to obtain word vectors:\n",
    "    - \"Continuous bag of words\" (CBOW) - the problem explained above\n",
    "    - \"skip n-gram\"\n",
    "\n",
    "-  \"skip n-gram\" is inverse of CBOW, where the problem will be to find the surrounding words eg: Find the missing words in \"___ ____ ____ king\".\n",
    "\n",
    "- This is how language models that make use of word vectors are trained. This is how, based on the word vector, a language model is able to perform operations like find the type of entity, similarity and many such operations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
